{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okurnaz2516/deepnet/blob/master/cnn_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAFIDUtZpCkx",
        "colab_type": "code",
        "outputId": "644143b7-a5d9-420f-c9c8-3f18196cbaca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D \n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "num_classes=10\n",
        "epochs=50\n",
        "batch_size=128\n",
        "img_rows=28\n",
        "img_cols=28\n",
        "\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols).astype('float32')\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols).astype('float32')\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1).astype('float32')\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1).astype('float32')\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "    \n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "\n",
        "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test=keras.utils.to_categorical(y_test,num_classes)\n",
        "\n",
        "cnn_model=Sequential()\n",
        "cnn_model.add(Conv2D(96,kernel_size=(11,11)#strides=(4,4),\n",
        "                     ,activation='relu',input_shape=input_shape))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,2)))#strides=(2,2)))\n",
        "cnn_model.add(Conv2D(256,kernel_size=(5,5),activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,2)))#strides=(2,2)))\n",
        "cnn_model.add(Conv2D(384,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "cnn_model.add(Conv2D(384,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "cnn_model.add(Conv2D(256,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,2)))#strides=(2,2)))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(4096,activation='relu'))\n",
        "cnn_model.add(Dense(4096,activation='relu'))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Dense(num_classes,activation='tanh'))\n",
        "\n",
        "cnn_model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.SGD(lr=0.001),metrics=['accuracy'])\n",
        "\n",
        "cnn_model.summary()\n",
        "\n",
        "cnn_model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,\n",
        "              verbose=1,validation_data=(x_test,y_test))\n",
        "\n",
        "cnn_model.summary()\n",
        "\n",
        "score=cnn_model.evaluate(x_test,y_test,verbose=0)\n",
        "print('Test loss:',score[0])\n",
        "print('Test accuracy:',score[1])\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_51 (Conv2D)           (None, 18, 18, 96)        11712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 9, 9, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 5, 5, 256)         614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 21,598,922\n",
            "Trainable params: 21,598,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 25s 412us/step - loss: 8.9525 - acc: 0.1115 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.1770 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 9.1377 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.1396 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2148 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2188 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.2102 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.2626 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2212 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2849 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2674 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 9.1914 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 9.1994 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.3450 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.2644 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 9.2849 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2964 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 9.2188 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 9.2341 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2462 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 9.2548 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.2701 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2625 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.2709 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.2625 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 9.2848 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.2411 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 9.1911 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 9.2209 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 9.2513 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.3356 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 9.2754 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 9.3437 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 9.2832 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 9.3251 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.3434 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2926 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 9.2695 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 9.2593 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2701 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 9.2811 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 9.3149 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.3063 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 9.3198 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 9.2647 - acc: 0.1124 - val_loss: 9.7369 - val_acc: 0.1135\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 5.1973 - acc: 0.1078 - val_loss: 1.1921e-07 - val_acc: 0.0980\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 1.1921e-07 - acc: 0.0987 - val_loss: 1.1921e-07 - val_acc: 0.0980\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 1.1921e-07 - acc: 0.0987 - val_loss: 1.1921e-07 - val_acc: 0.0980\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 1.1921e-07 - acc: 0.0987 - val_loss: 1.1921e-07 - val_acc: 0.0980\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 1.1921e-07 - acc: 0.0987 - val_loss: 1.1921e-07 - val_acc: 0.0980\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_51 (Conv2D)           (None, 18, 18, 96)        11712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 9, 9, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 5, 5, 256)         614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 21,598,922\n",
            "Trainable params: 21,598,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test loss: 1.1920930376163597e-07\n",
            "Test accuracy: 0.098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdWo_k5hBa2q",
        "colab_type": "text"
      },
      "source": [
        "Epochs=30\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 0.043233456114842556 Test accuracy: 0.986\n",
        "\n",
        "Epochs=30 \n",
        "Learning Rate=0.001 \n",
        "Optimizer=SGD \n",
        "Activation=Softmax\n",
        "Test loss: 2.1397287292480467 Test accuracy: 0.5068\n",
        "\n",
        "Epochs=30 \n",
        "Learning Rate=0.0001 \n",
        "Optimizer=SGD \n",
        "Activation=Softmax\n",
        "Test loss: 2.2999775451660156 Test accuracy: 0.1135\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 0.038820368931387204 Test accuracy: 0.9874\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.001\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 0.3298974743425846 Test accuracy: 0.9009\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.0001\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 2.2992451038360597 Test accuracy: 0.1135\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=Sigmoid\n",
        "Test loss: 0.03743595634045196 Test accuracy: 0.9878\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.001\n",
        "Optimizer=SGD\n",
        "Activation=Sigmoid\n",
        "Test loss: 2.2688174613952636 Test accuracy: 0.2979\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=tanh\n",
        "Test loss: 9.712764389038085 Test accuracy: 0.098\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.001\n",
        "Optimizer=SGD\n",
        "Activation=tanh\n",
        "Test loss: 1.1920930376163597e-07 Test accuracy: 0.098"
      ]
    }
  ]
}