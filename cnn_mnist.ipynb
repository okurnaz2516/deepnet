{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okurnaz2516/deepnet/blob/master/cnn_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAFIDUtZpCkx",
        "colab_type": "code",
        "outputId": "e5490459-a248-4e4e-c466-29360f3c84db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D \n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "num_classes=10\n",
        "epochs=50\n",
        "batch_size=128\n",
        "img_rows=28\n",
        "img_cols=28\n",
        "\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "\n",
        "X_train,X_val,Y_train,Y_val=train_test_split(x_train,y_train,test_size=0.2,random_state=2)\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols).astype('float32')\n",
        "    X_val = X_val.reshape(X_val.shape[0], 1, img_rows, img_cols).astype('float32')\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols).astype('float32')\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1).astype('float32')\n",
        "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1).astype('float32')\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1).astype('float32')\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "    \n",
        "\n",
        "X_train/=255\n",
        "X_val/=255\n",
        "x_test/=255\n",
        "\n",
        "Y_train=keras.utils.to_categorical(Y_train,num_classes)\n",
        "Y_val=keras.utils.to_categorical(Y_val,num_classes)\n",
        "y_test=keras.utils.to_categorical(y_test,num_classes)\n",
        "\n",
        "cnn_model=Sequential()\n",
        "cnn_model.add(Conv2D(96,kernel_size=(11,11)\n",
        "                     ,activation='relu',input_shape=input_shape))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn_model.add(Conv2D(256,kernel_size=(5,5),activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn_model.add(Conv2D(384,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "cnn_model.add(Conv2D(384,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "cnn_model.add(Conv2D(256,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(4096,activation='relu'))\n",
        "cnn_model.add(Dense(4096,activation='relu'))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "cnn_model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.SGD(lr=0.01),metrics=['accuracy'])\n",
        "\n",
        "cnn_model.summary()\n",
        "\n",
        "cnn_model.fit(X_train,Y_train,batch_size=batch_size,epochs=epochs,\n",
        "              verbose=1,validation_data=(X_val,Y_val))\n",
        "\n",
        "cnn_model.summary()\n",
        "\n",
        "score=cnn_model.evaluate(x_test,y_test,verbose=0)\n",
        "print('Test loss:',score[0])\n",
        "print('Test accuracy:',score[1])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 18, 18, 96)        11712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 9, 9, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 5, 5, 256)         614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 21,598,922\n",
            "Trainable params: 21,598,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "48000/48000 [==============================] - 28s 583us/step - loss: 2.2999 - acc: 0.1136 - val_loss: 2.2964 - val_acc: 0.1128\n",
            "Epoch 2/50\n",
            "48000/48000 [==============================] - 19s 388us/step - loss: 2.2927 - acc: 0.1124 - val_loss: 2.2850 - val_acc: 0.1134\n",
            "Epoch 3/50\n",
            "48000/48000 [==============================] - 19s 388us/step - loss: 2.2733 - acc: 0.2104 - val_loss: 2.2436 - val_acc: 0.4123\n",
            "Epoch 4/50\n",
            "48000/48000 [==============================] - 19s 392us/step - loss: 2.1260 - acc: 0.4042 - val_loss: 1.6521 - val_acc: 0.5190\n",
            "Epoch 5/50\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 1.0197 - acc: 0.6656 - val_loss: 0.6106 - val_acc: 0.8056\n",
            "Epoch 6/50\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 0.5371 - acc: 0.8291 - val_loss: 0.4077 - val_acc: 0.8710\n",
            "Epoch 7/50\n",
            "48000/48000 [==============================] - 19s 389us/step - loss: 0.3794 - acc: 0.8860 - val_loss: 0.2996 - val_acc: 0.9070\n",
            "Epoch 8/50\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 0.2950 - acc: 0.9104 - val_loss: 0.2293 - val_acc: 0.9296\n",
            "Epoch 9/50\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 0.2421 - acc: 0.9272 - val_loss: 0.1982 - val_acc: 0.9378\n",
            "Epoch 10/50\n",
            "48000/48000 [==============================] - 19s 389us/step - loss: 0.2034 - acc: 0.9381 - val_loss: 0.1988 - val_acc: 0.9385\n",
            "Epoch 11/50\n",
            "48000/48000 [==============================] - 19s 392us/step - loss: 0.1770 - acc: 0.9469 - val_loss: 0.1537 - val_acc: 0.9527\n",
            "Epoch 12/50\n",
            "48000/48000 [==============================] - 19s 389us/step - loss: 0.1543 - acc: 0.9538 - val_loss: 0.1659 - val_acc: 0.9482\n",
            "Epoch 13/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.1414 - acc: 0.9578 - val_loss: 0.1237 - val_acc: 0.9629\n",
            "Epoch 14/50\n",
            "48000/48000 [==============================] - 19s 388us/step - loss: 0.1263 - acc: 0.9613 - val_loss: 0.1147 - val_acc: 0.9647\n",
            "Epoch 15/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.1157 - acc: 0.9650 - val_loss: 0.1402 - val_acc: 0.9567\n",
            "Epoch 16/50\n",
            "48000/48000 [==============================] - 19s 395us/step - loss: 0.1069 - acc: 0.9678 - val_loss: 0.1025 - val_acc: 0.9686\n",
            "Epoch 17/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0975 - acc: 0.9705 - val_loss: 0.1109 - val_acc: 0.9663\n",
            "Epoch 18/50\n",
            "48000/48000 [==============================] - 19s 388us/step - loss: 0.0909 - acc: 0.9721 - val_loss: 0.0884 - val_acc: 0.9728\n",
            "Epoch 19/50\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 0.0849 - acc: 0.9746 - val_loss: 0.1010 - val_acc: 0.9678\n",
            "Epoch 20/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0790 - val_acc: 0.9758\n",
            "Epoch 21/50\n",
            "48000/48000 [==============================] - 19s 389us/step - loss: 0.0748 - acc: 0.9770 - val_loss: 0.0819 - val_acc: 0.9744\n",
            "Epoch 22/50\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 0.0714 - acc: 0.9785 - val_loss: 0.0790 - val_acc: 0.9753\n",
            "Epoch 23/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0672 - acc: 0.9793 - val_loss: 0.0708 - val_acc: 0.9777\n",
            "Epoch 24/50\n",
            "48000/48000 [==============================] - 19s 392us/step - loss: 0.0637 - acc: 0.9808 - val_loss: 0.0677 - val_acc: 0.9795\n",
            "Epoch 25/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0596 - acc: 0.9815 - val_loss: 0.0676 - val_acc: 0.9797\n",
            "Epoch 26/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0568 - acc: 0.9827 - val_loss: 0.0835 - val_acc: 0.9746\n",
            "Epoch 27/50\n",
            "48000/48000 [==============================] - 19s 392us/step - loss: 0.0544 - acc: 0.9832 - val_loss: 0.0647 - val_acc: 0.9813\n",
            "Epoch 28/50\n",
            "48000/48000 [==============================] - 19s 392us/step - loss: 0.0528 - acc: 0.9843 - val_loss: 0.0635 - val_acc: 0.9802\n",
            "Epoch 29/50\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 0.0498 - acc: 0.9851 - val_loss: 0.0613 - val_acc: 0.9807\n",
            "Epoch 30/50\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 0.0461 - acc: 0.9858 - val_loss: 0.0594 - val_acc: 0.9817\n",
            "Epoch 31/50\n",
            "48000/48000 [==============================] - 19s 389us/step - loss: 0.0464 - acc: 0.9859 - val_loss: 0.0558 - val_acc: 0.9829\n",
            "Epoch 32/50\n",
            "48000/48000 [==============================] - 19s 389us/step - loss: 0.0423 - acc: 0.9869 - val_loss: 0.0623 - val_acc: 0.9816\n",
            "Epoch 33/50\n",
            "48000/48000 [==============================] - 19s 392us/step - loss: 0.0414 - acc: 0.9880 - val_loss: 0.0550 - val_acc: 0.9836\n",
            "Epoch 34/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0401 - acc: 0.9881 - val_loss: 0.0542 - val_acc: 0.9833\n",
            "Epoch 35/50\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 0.0376 - acc: 0.9887 - val_loss: 0.0510 - val_acc: 0.9846\n",
            "Epoch 36/50\n",
            "48000/48000 [==============================] - 19s 392us/step - loss: 0.0369 - acc: 0.9886 - val_loss: 0.0513 - val_acc: 0.9842\n",
            "Epoch 37/50\n",
            "48000/48000 [==============================] - 19s 393us/step - loss: 0.0345 - acc: 0.9893 - val_loss: 0.0529 - val_acc: 0.9845\n",
            "Epoch 38/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0344 - acc: 0.9894 - val_loss: 0.0525 - val_acc: 0.9837\n",
            "Epoch 39/50\n",
            "48000/48000 [==============================] - 19s 395us/step - loss: 0.0329 - acc: 0.9902 - val_loss: 0.0522 - val_acc: 0.9848\n",
            "Epoch 40/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0313 - acc: 0.9906 - val_loss: 0.0496 - val_acc: 0.9854\n",
            "Epoch 41/50\n",
            "48000/48000 [==============================] - 19s 394us/step - loss: 0.0302 - acc: 0.9906 - val_loss: 0.0473 - val_acc: 0.9859\n",
            "Epoch 42/50\n",
            "48000/48000 [==============================] - 19s 389us/step - loss: 0.0282 - acc: 0.9917 - val_loss: 0.0544 - val_acc: 0.9842\n",
            "Epoch 43/50\n",
            "48000/48000 [==============================] - 19s 387us/step - loss: 0.0269 - acc: 0.9921 - val_loss: 0.0556 - val_acc: 0.9837\n",
            "Epoch 44/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0268 - acc: 0.9917 - val_loss: 0.0507 - val_acc: 0.9845\n",
            "Epoch 45/50\n",
            "48000/48000 [==============================] - 19s 388us/step - loss: 0.0269 - acc: 0.9917 - val_loss: 0.0508 - val_acc: 0.9850\n",
            "Epoch 46/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0236 - acc: 0.9931 - val_loss: 0.0528 - val_acc: 0.9846\n",
            "Epoch 47/50\n",
            "48000/48000 [==============================] - 19s 389us/step - loss: 0.0229 - acc: 0.9934 - val_loss: 0.0497 - val_acc: 0.9862\n",
            "Epoch 48/50\n",
            "48000/48000 [==============================] - 19s 390us/step - loss: 0.0226 - acc: 0.9932 - val_loss: 0.0451 - val_acc: 0.9858\n",
            "Epoch 49/50\n",
            "48000/48000 [==============================] - 19s 389us/step - loss: 0.0211 - acc: 0.9934 - val_loss: 0.0466 - val_acc: 0.9868\n",
            "Epoch 50/50\n",
            "48000/48000 [==============================] - 19s 391us/step - loss: 0.0200 - acc: 0.9940 - val_loss: 0.0452 - val_acc: 0.9862\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 18, 18, 96)        11712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 9, 9, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 5, 5, 256)         614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 21,598,922\n",
            "Trainable params: 21,598,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test loss: 0.03644177508490393\n",
            "Test accuracy: 0.988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdWo_k5hBa2q",
        "colab_type": "text"
      },
      "source": [
        "Epochs=30\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 0.043233456114842556 Test accuracy: 0.986\n",
        "\n",
        "Epochs=30 \n",
        "Learning Rate=0.001 \n",
        "Optimizer=SGD \n",
        "Activation=Softmax\n",
        "Test loss: 2.1397287292480467 Test accuracy: 0.5068\n",
        "\n",
        "Epochs=30 \n",
        "Learning Rate=0.0001 \n",
        "Optimizer=SGD \n",
        "Activation=Softmax\n",
        "Test loss: 2.2999775451660156 Test accuracy: 0.1135\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 0.038820368931387204 Test accuracy: 0.9874\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.001\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 0.3298974743425846 Test accuracy: 0.9009\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.0001\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 2.2992451038360597 Test accuracy: 0.1135\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=Sigmoid\n",
        "Test loss: 0.03743595634045196 Test accuracy: 0.9878\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.001\n",
        "Optimizer=SGD\n",
        "Activation=Sigmoid\n",
        "Test loss: 2.2688174613952636 Test accuracy: 0.2979\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=tanh\n",
        "Test loss: 9.712764389038085 Test accuracy: 0.098\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.001\n",
        "Optimizer=SGD\n",
        "Activation=tanh\n",
        "Test loss: 1.1920930376163597e-07 Test accuracy: 0.098"
      ]
    }
  ]
}