{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okurnaz2516/deepnet/blob/master/cnn_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAFIDUtZpCkx",
        "colab_type": "code",
        "outputId": "c1978e95-576a-4158-ba20-2ca18b211041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D \n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "num_classes=10\n",
        "epochs=50\n",
        "batch_size=128\n",
        "img_rows=28\n",
        "img_cols=28\n",
        "\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols).astype('float32')\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols).astype('float32')\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1).astype('float32')\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1).astype('float32')\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "    \n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "\n",
        "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test=keras.utils.to_categorical(y_test,num_classes)\n",
        "\n",
        "cnn_model=Sequential()\n",
        "cnn_model.add(Conv2D(96,kernel_size=(11,11)#strides=(4,4),\n",
        "                     ,activation='relu',input_shape=input_shape))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,2)))#strides=(2,2)))\n",
        "cnn_model.add(Conv2D(256,kernel_size=(5,5),activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,2)))#strides=(2,2)))\n",
        "cnn_model.add(Conv2D(384,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "cnn_model.add(Conv2D(384,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "cnn_model.add(Conv2D(256,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,2)))#strides=(2,2)))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(4096,activation='relu'))\n",
        "cnn_model.add(Dense(4096,activation='relu'))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Dense(num_classes,activation='sigmoid'))\n",
        "\n",
        "cnn_model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.SGD(lr=0.001),metrics=['accuracy'])\n",
        "\n",
        "cnn_model.summary()\n",
        "\n",
        "cnn_model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,\n",
        "              verbose=1,validation_data=(x_test,y_test))\n",
        "\n",
        "cnn_model.summary()\n",
        "\n",
        "score=cnn_model.evaluate(x_test,y_test,verbose=0)\n",
        "print('Test loss:',score[0])\n",
        "print('Test accuracy:',score[1])\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_41 (Conv2D)           (None, 18, 18, 96)        11712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 9, 9, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 5, 5, 256)         614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 21,598,922\n",
            "Trainable params: 21,598,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 2.3025 - acc: 0.1196 - val_loss: 2.3023 - val_acc: 0.1135\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.3023 - acc: 0.1173 - val_loss: 2.3021 - val_acc: 0.1135\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 2.3021 - acc: 0.1125 - val_loss: 2.3019 - val_acc: 0.1135\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.3020 - acc: 0.1124 - val_loss: 2.3017 - val_acc: 0.1135\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.3018 - acc: 0.1124 - val_loss: 2.3015 - val_acc: 0.1135\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 2.3016 - acc: 0.1124 - val_loss: 2.3013 - val_acc: 0.1135\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.3015 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 2.3011 - acc: 0.1124 - val_loss: 2.3007 - val_acc: 0.1135\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 2.3010 - acc: 0.1124 - val_loss: 2.3005 - val_acc: 0.1135\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 2.3008 - acc: 0.1124 - val_loss: 2.3003 - val_acc: 0.1135\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.3006 - acc: 0.1124 - val_loss: 2.3001 - val_acc: 0.1135\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 2.3004 - acc: 0.1124 - val_loss: 2.2999 - val_acc: 0.1135\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.3002 - acc: 0.1124 - val_loss: 2.2997 - val_acc: 0.1135\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 2.3000 - acc: 0.1124 - val_loss: 2.2995 - val_acc: 0.1135\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.2999 - acc: 0.1124 - val_loss: 2.2993 - val_acc: 0.1135\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.2996 - acc: 0.1124 - val_loss: 2.2990 - val_acc: 0.1135\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.2994 - acc: 0.1124 - val_loss: 2.2988 - val_acc: 0.1135\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 23s 390us/step - loss: 2.2992 - acc: 0.1124 - val_loss: 2.2985 - val_acc: 0.1135\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 2.2990 - acc: 0.1124 - val_loss: 2.2983 - val_acc: 0.1135\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.2987 - acc: 0.1124 - val_loss: 2.2980 - val_acc: 0.1135\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 2.2985 - acc: 0.1124 - val_loss: 2.2977 - val_acc: 0.1135\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 2.2982 - acc: 0.1124 - val_loss: 2.2973 - val_acc: 0.1135\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 23s 390us/step - loss: 2.2979 - acc: 0.1124 - val_loss: 2.2970 - val_acc: 0.1135\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.2976 - acc: 0.1124 - val_loss: 2.2966 - val_acc: 0.1135\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.2973 - acc: 0.1124 - val_loss: 2.2963 - val_acc: 0.1135\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 2.2969 - acc: 0.1124 - val_loss: 2.2959 - val_acc: 0.1135\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 2.2966 - acc: 0.1124 - val_loss: 2.2954 - val_acc: 0.1135\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 2.2962 - acc: 0.1124 - val_loss: 2.2950 - val_acc: 0.1135\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.2958 - acc: 0.1124 - val_loss: 2.2945 - val_acc: 0.1135\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.2954 - acc: 0.1124 - val_loss: 2.2939 - val_acc: 0.1135\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.2949 - acc: 0.1124 - val_loss: 2.2934 - val_acc: 0.1135\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 23s 390us/step - loss: 2.2944 - acc: 0.1124 - val_loss: 2.2928 - val_acc: 0.1135\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 2.2939 - acc: 0.1124 - val_loss: 2.2921 - val_acc: 0.1135\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.2933 - acc: 0.1125 - val_loss: 2.2915 - val_acc: 0.1135\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.2927 - acc: 0.1129 - val_loss: 2.2907 - val_acc: 0.1153\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 2.2920 - acc: 0.1144 - val_loss: 2.2899 - val_acc: 0.1201\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 2.2914 - acc: 0.1167 - val_loss: 2.2890 - val_acc: 0.1325\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 2.2906 - acc: 0.1208 - val_loss: 2.2881 - val_acc: 0.1467\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 2.2898 - acc: 0.1284 - val_loss: 2.2871 - val_acc: 0.1630\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.2888 - acc: 0.1406 - val_loss: 2.2859 - val_acc: 0.1775\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.2879 - acc: 0.1538 - val_loss: 2.2847 - val_acc: 0.1944\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.2868 - acc: 0.1700 - val_loss: 2.2834 - val_acc: 0.2102\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 2.2856 - acc: 0.1857 - val_loss: 2.2819 - val_acc: 0.2236\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.2843 - acc: 0.2025 - val_loss: 2.2803 - val_acc: 0.2396\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.2829 - acc: 0.2197 - val_loss: 2.2785 - val_acc: 0.2525\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 2.2812 - acc: 0.2341 - val_loss: 2.2765 - val_acc: 0.2644\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 2.2795 - acc: 0.2492 - val_loss: 2.2742 - val_acc: 0.2760\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.2775 - acc: 0.2628 - val_loss: 2.2717 - val_acc: 0.2882\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 2.2752 - acc: 0.2770 - val_loss: 2.2688 - val_acc: 0.2979\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_41 (Conv2D)           (None, 18, 18, 96)        11712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 9, 9, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 5, 5, 256)         614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 21,598,922\n",
            "Trainable params: 21,598,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test loss: 2.2688174613952636\n",
            "Test accuracy: 0.2979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdWo_k5hBa2q",
        "colab_type": "text"
      },
      "source": [
        "Epochs=30\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 0.043233456114842556 Test accuracy: 0.986\n",
        "\n",
        "Epochs=30 \n",
        "Learning Rate=0.001 \n",
        "Optimizer=SGD \n",
        "Activation=Softmax\n",
        "Test loss: 2.1397287292480467 Test accuracy: 0.5068\n",
        "\n",
        "Epochs=30 \n",
        "Learning Rate=0.0001 \n",
        "Optimizer=SGD \n",
        "Activation=Softmax\n",
        "Test loss: 2.2999775451660156 Test accuracy: 0.1135\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 0.038820368931387204 Test accuracy: 0.9874\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.001\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 0.3298974743425846 Test accuracy: 0.9009\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.0001\n",
        "Optimizer=SGD\n",
        "Activation=Softmax\n",
        "Test loss: 2.2992451038360597 Test accuracy: 0.1135\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.01\n",
        "Optimizer=SGD\n",
        "Activation=Sigmoid\n",
        "Test loss: 0.03743595634045196 Test accuracy: 0.9878\n",
        "\n",
        "Epochs=50\n",
        "Learning Rate=0.001\n",
        "Optimizer=SGD\n",
        "Activation=Sigmoid\n",
        "Test loss: 0.2688174613952636 Test accuracy: 0.2979\n",
        "\n"
      ]
    }
  ]
}